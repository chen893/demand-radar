# Demand Radar PRD v1.5 评审报告

> 评审日期: 2025-12-09
> 评审版本: PRD v1.5
> 评审状态: 待修订

---

## 一、核心价值主张的根本问题

### 1.1 「需求识别」的可行性存疑

PRD 声称 LLM 能从网页内容中「识别潜在需求」并进行「痛点评分」，但这里有一个根本性问题：

**LLM 能做的是「信息提取和归纳」，而非「需求发现」。**

| 场景 | 用户期望 | LLM 实际能力 |
|-----|---------|-------------|
| Reddit 吐槽帖 | 发现「可做成产品的商业机会」 | 只能提取「用户在抱怨什么」 |
| 知乎问答 | 判断「这个需求有多大市场」 | 只能总结「回答者说了什么」 |

**问题**：「痛点强度 8/10」「付费意愿 7/10」这些评分的**依据是什么**？
- 单篇帖子的评论数？（样本量太小）
- 帖子的点赞数？（不代表付费意愿）
- LLM 的「感觉」？（不可靠）

**建议**：
- 明确评分维度的**数据来源**，而非让 LLM 凭空打分
- 或者诚实地将功能定位为「内容摘要 + 痛点提取」，而非「需求发现」

### 1.2 与 ChatGPT 的差异化不足

用户完全可以：
1. 复制网页内容
2. 粘贴到 ChatGPT
3. 问「这里面有什么用户痛点？」

**Demand Radar 相比这个流程的增量价值是什么？**

| 声称的价值 | 实际情况 |
|-----------|---------|
| 「一键提取」省去复制粘贴 | 节省 5 秒，但需要配置 API Key、学习新工具 |
| 「本地存储需求库」 | 用户可以用 Notion/备忘录达到同样效果 |
| 「痛点评分」 | ChatGPT 也能给出类似分析 |

**真正的差异化应该是**：
- **跨页面聚合**：同一个需求在不同地方出现了多少次？（但这是 P1 功能）
- **趋势追踪**：这个需求是在变热还是变冷？（但这是 P1 功能）
- **结构化积累**：长期积累后形成个人需求知识库（需要时间验证）

**问题**：MVP 阶段的核心差异化功能都被放到了 P1，导致 MVP 的价值主张薄弱。

---

## 二、目标用户与平台的错配

### 2.1 用户画像与平台支持的矛盾

| P0 用户 | 主要信息源 | MVP 支持情况 |
|--------|-----------|-------------|
| 独立开发者 | Reddit, Indie Hackers, Hacker News, Twitter | 全部是 P1 |
| 产品经理 | 知乎、用户访谈记录、竞品评论区 | 知乎支持 |

**结论**：MVP 实际上只服务产品经理，但文档把独立开发者列为 P0 用户。

### 2.2 知乎作为 MVP 首发平台的问题

**知乎的内容特点**：
- 多为「经验分享」「观点输出」，而非「痛点吐槽」
- 高赞回答往往是「怎么解决问题」，而非「我有什么问题」
- 需求信号密度远低于 Reddit

**对比**：
```
Reddit r/SaaS:
"I've been looking for a tool that does X but everything is either
too expensive or too complicated. Would pay $50 for something simple."
→ 明确的需求信号

知乎「有哪些好用的 XX 工具」:
"推荐 A 工具，功能全面；B 工具性价比高；C 工具适合新手..."
→ 解决方案推荐，而非需求表达
```

**建议**：要么调整用户优先级（产品经理为主），要么把 Reddit 提到 MVP。

---

## 三、用户旅程的断裂点

### 3.1 首次使用门槛过高

```
安装插件 → 配置 API Key → 授权站点 → 浏览到合适页面 → 点击分析 → 查看结果
   ↑            ↑              ↑
  简单      需要有 OpenAI 账号    需要理解白名单概念
            需要知道如何获取 Key
            需要理解 API 计费
```

**API Key 配置完成率 ≥ 70%** 这个目标可能过于乐观：
- Raycast AI 的付费转化率约 5-10%
- 大部分用户没有 OpenAI API 账号
- 即使有账号，很多人不知道怎么获取 API Key

### 3.2 价值验证延迟

用户完成配置后：
1. 需要**恰好**在浏览有价值的页面时想起打开插件
2. 需要等待 LLM 分析（5-15秒）
3. 需要判断分析结果是否有用
4. 需要重复多次才能积累足够数据看到「需求库」的价值

**问题**：用户在获得核心价值之前，需要跨越太多障碍。

**建议**：
- 提供预置的 Demo 数据，让用户立即看到「需求库积累后的样子」
- 考虑首次使用提供免费额度（接入免费模型或自建代理）

---

## 四、数据模型的隐患

### 4.1 Extraction 与 Demand 的关系处理

当前设计：
```
Extraction (页面) 1:N Demand (需求)
```

**问题**：同一个需求可能来自多个页面，但当前模型无法表达：

```
Demand A ←── Extraction 1 (Reddit 帖子 1)
Demand A ←── Extraction 2 (Reddit 帖子 2)  // 同一个需求，不同来源
Demand A ←── Extraction 3 (知乎问答)
```

当前模型下，这会产生 3 个独立的 Demand 记录，无法自动聚合。

**这直接影响核心价值**：「发现反复出现的需求模式」需要手动识别相似需求。

### 4.2 缺少总容量限制

文档定义了单条记录 ≤ 500KB，但没有定义：
- IndexedDB 总容量上限（浏览器默认可能在 50MB-无限之间）
- 超出总容量时的处理策略
- 老数据清理机制

**风险**：重度用户积累大量数据后可能遇到存储问题。

---

## 五、商业模式的可持续性

### 5.1 用户自备 API Key 的问题

**短期**：
- 降低了产品的启动门槛（无需搭建后端）
- 但提高了用户的使用门槛

**长期**：
- 无法建立用户付费习惯
- 无法积累用户数据（用于改进算法）
- 难以转向订阅模式（用户已习惯「免费」使用）

### 5.2 缺少商业化路径

PRD 完全没有提及：
- 如何从免费转向付费？
- P1 的云同步是否收费？
- 未来的定价策略？

---

## 六、验收标准的问题

### 6.1 「Top3 需求命中率 ≥ 70%」如何定义？

```
人工标注: 页面包含需求 A, B, C
LLM 输出: 需求 X, Y, Z

什么情况算「命中」？
- X 和 A 的语义相似度 ≥ 0.7？
- 还是人工判定「X 和 A 表达同一需求」？
```

**问题**：
- 语义相似度 0.7 的阈值依据是什么？
- 人工判定的一致性如何保证？
- 100 条样本是否足够？

### 6.2 缺少负向指标

只定义了「命中率」，没有定义：
- **误报率**：LLM 输出的「伪需求」比例
- **过度解读率**：把普通抱怨解读为商业机会的比例

---

## 七、路线图风险

### 7.1 5 周开发 MVP 的可行性

| 周次 | 任务 | 风险 |
|-----|------|------|
| Week 1 | 提取器 | 知乎反爬策略可能导致延期 |
| Week 2 | Side Panel | 相对可控 |
| Week 3 | LLM 接入 | Prompt 调优可能需要多次迭代 |
| Week 4 | 安全+打磨 | 已删除大部分安全功能，实际工作量减少 |
| Week 5 | 测试+上架 | Chrome 审核可能耗时 1-2 周 |

**主要风险**：
- 知乎的反爬措施（登录墙、动态加载）
- LLM Prompt 的效果调优
- Chrome 商店审核周期

### 7.2 缺少技术验证里程碑

建议在 Week 1 前增加：
```
Week 0: 技术验证 (3-5 天)
├── 验证知乎内容提取可行性（是否需要登录、是否有反爬）
├── 验证 LLM 需求识别效果（手动测试 10 个样本）
└── 验证 Side Panel API 兼容性
```

---

## 八、文档一致性问题

### 8.1 已删除功能但文档残留

| 位置 | 问题 | 状态 |
|-----|------|------|
| 4.1 功能架构图 | 仍写着「轻量备份」 | 待修复 |
| 4.2 设置页面验收标准 | 「敏感配置加密」 | 待修复 |
| 8.2 技术栈 | 「加密: Web Crypto API」 | 待修复 |
| 十、风险表 | 「API Key 泄露...加密存储、内存保护」 | 待修复 |
| 十、风险表 | 「Chrome Sync LRU 清理」 | 待修复 |
| Week 4 路线图 | 「API Key 加密」 | 待修复 |

### 8.2 细节错误

| 位置 | 问题 |
|-----|------|
| 4.4 截断规则 | 「保存失败，请**稀**后重试」→ 错别字，应为「稍」 |
| manifest.json | host_permissions 包含 Reddit，但 Reddit 是 P1 |
| content_scripts matches | 包含 Reddit，但 MVP 不支持 |

---

## 九、综合建议

### 必须解决（阻塞性问题）

| # | 问题 | 建议 | 优先级 |
|---|-----|------|-------|
| 1 | 用户画像与平台支持错配 | 将 Reddit 提升为 MVP P0，或将独立开发者降为 P1 用户 | P0 |
| 2 | 核心价值主张模糊 | 明确定位：是「内容摘要工具」还是「需求发现工具」 | P0 |
| 3 | 痛点评分缺乏依据 | 定义评分的数据来源，或改为定性标签 | P0 |
| 4 | 文档内容不一致 | 修复架构图、技术栈、风险表中的过时内容 | P0 |

### 强烈建议（影响成功率）

| # | 问题 | 建议 | 优先级 |
|---|-----|------|-------|
| 5 | 首次使用门槛过高 | 提供 Demo 数据或免费试用额度 | P1 |
| 6 | 需求聚合能力缺失 | 考虑在 MVP 加入简单的「相似需求」提示 | P1 |
| 7 | 缺少 LLM Prompt 规范 | 补充需求识别、痛点评分的 Prompt 设计 | P1 |
| 8 | 缺少技术验证阶段 | 在正式开发前进行 1 周技术验证 | P1 |

### 可以接受（后续迭代解决）

| # | 问题 | 说明 | 优先级 |
|---|-----|------|-------|
| 9 | 总存储容量限制 | MVP 阶段数据量有限，P1 再处理 | P2 |
| 10 | 商业化路径 | MVP 阶段聚焦验证价值，商业化可后置 | P2 |
| 11 | 国际化 | 根据实际用户分布决定 | P2 |

---

## 十、评审结论

**整体评价**：文档结构完整、细节丰富，但存在**核心价值主张模糊**和**用户-平台错配**两个根本性问题，建议在开发前先解决。

**建议动作**：
1. 召开产品评审会，明确 MVP 的核心差异化价值
2. 重新评估目标用户优先级和首发平台选择
3. 修复文档一致性问题
4. 增加 Week 0 技术验证阶段

---

## 变更记录

| 日期 | 内容 | 评审人 |
|-----|------|-------|
| 2025-12-09 | 初次评审 | - |
